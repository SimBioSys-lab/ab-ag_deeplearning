Initializing dataset...
Initializing SASAModel with 1 repeated layers...
Using 4 GPUs with DataParallel.
Epoch [1/1000], Training Loss: 142.6578
Validation Loss: 0.0724
New best model found with validation loss: 0.0724
Epoch [2/1000], Training Loss: 0.0721
Validation Loss: 0.0715
New best model found with validation loss: 0.0715
Epoch [3/1000], Training Loss: 0.0717
Validation Loss: 0.0723
No improvement in validation loss. Early stop counter: 1/30
Epoch [4/1000], Training Loss: 0.0715
Validation Loss: 0.0716
No improvement in validation loss. Early stop counter: 2/30
Epoch [5/1000], Training Loss: 0.0717
Validation Loss: 0.0718
No improvement in validation loss. Early stop counter: 3/30
Epoch [6/1000], Training Loss: 0.0709
Validation Loss: 0.0707
New best model found with validation loss: 0.0707
Epoch [7/1000], Training Loss: 0.0709
Validation Loss: 0.0771
No improvement in validation loss. Early stop counter: 1/30
Epoch [8/1000], Training Loss: 0.0716
Validation Loss: 0.0703
New best model found with validation loss: 0.0703
Epoch [9/1000], Training Loss: 0.0705
Validation Loss: 0.0715
No improvement in validation loss. Early stop counter: 1/30
Epoch [10/1000], Training Loss: 0.0704
Validation Loss: 0.0706
No improvement in validation loss. Early stop counter: 2/30
Epoch [11/1000], Training Loss: 0.0700
Validation Loss: 0.0712
No improvement in validation loss. Early stop counter: 3/30
Epoch [12/1000], Training Loss: 0.0699
Validation Loss: 0.0698
New best model found with validation loss: 0.0698
Epoch [13/1000], Training Loss: 0.0696
Validation Loss: 0.0694
New best model found with validation loss: 0.0694
Epoch [14/1000], Training Loss: 0.0694
Validation Loss: 0.0695
No improvement in validation loss. Early stop counter: 1/30
Epoch [15/1000], Training Loss: 0.0699
Validation Loss: 0.0702
No improvement in validation loss. Early stop counter: 2/30
Epoch [16/1000], Training Loss: 0.0695
Validation Loss: 0.0694
New best model found with validation loss: 0.0694
Epoch [17/1000], Training Loss: 0.0694
Validation Loss: 0.0695
No improvement in validation loss. Early stop counter: 1/30
Epoch [18/1000], Training Loss: 0.0699
Validation Loss: 0.0698
No improvement in validation loss. Early stop counter: 2/30
Epoch [19/1000], Training Loss: 0.0696
Validation Loss: 0.0693
New best model found with validation loss: 0.0693
Epoch [20/1000], Training Loss: 0.0695
Validation Loss: 0.0697
No improvement in validation loss. Early stop counter: 1/30
Epoch [21/1000], Training Loss: 0.0694
Validation Loss: 0.0700
No improvement in validation loss. Early stop counter: 2/30
Epoch [22/1000], Training Loss: 0.0694
Validation Loss: 0.0692
New best model found with validation loss: 0.0692
Epoch [23/1000], Training Loss: 0.0698
Validation Loss: 0.0703
No improvement in validation loss. Early stop counter: 1/30
Epoch [24/1000], Training Loss: 0.0691
Validation Loss: 0.0702
No improvement in validation loss. Early stop counter: 2/30
Epoch [25/1000], Training Loss: 0.0694
Validation Loss: 0.0690
New best model found with validation loss: 0.0690
Epoch [26/1000], Training Loss: 0.0689
Validation Loss: 0.0702
No improvement in validation loss. Early stop counter: 1/30
Epoch [27/1000], Training Loss: 0.0692
Validation Loss: 0.0697
No improvement in validation loss. Early stop counter: 2/30
Epoch [28/1000], Training Loss: 0.0690
Validation Loss: 0.0688
New best model found with validation loss: 0.0688
Epoch [29/1000], Training Loss: 0.0688
Validation Loss: 0.0689
No improvement in validation loss. Early stop counter: 1/30
Epoch [30/1000], Training Loss: 0.0693
Validation Loss: 0.0689
No improvement in validation loss. Early stop counter: 2/30
Epoch [31/1000], Training Loss: 0.0685
Validation Loss: 0.0706
No improvement in validation loss. Early stop counter: 3/30
Epoch [32/1000], Training Loss: 0.0687
Validation Loss: 0.0687
New best model found with validation loss: 0.0687
Epoch [33/1000], Training Loss: 0.0698
Validation Loss: 0.0755
No improvement in validation loss. Early stop counter: 1/30
Epoch [34/1000], Training Loss: 0.0788
Validation Loss: 0.0724
No improvement in validation loss. Early stop counter: 2/30
Epoch [35/1000], Training Loss: 0.0747
Validation Loss: 0.0705
No improvement in validation loss. Early stop counter: 3/30
Epoch [36/1000], Training Loss: 0.0697
Validation Loss: 0.0695
No improvement in validation loss. Early stop counter: 4/30
Epoch [37/1000], Training Loss: 0.0699
Validation Loss: 0.0714
No improvement in validation loss. Early stop counter: 5/30
Epoch [38/1000], Training Loss: 0.0694
Validation Loss: 0.0696
No improvement in validation loss. Early stop counter: 6/30
Epoch [39/1000], Training Loss: 0.0693
Validation Loss: 0.0698
No improvement in validation loss. Early stop counter: 7/30
Epoch [40/1000], Training Loss: 0.0691
Validation Loss: 0.0688
No improvement in validation loss. Early stop counter: 8/30
Epoch [41/1000], Training Loss: 0.0687
Validation Loss: 0.0704
No improvement in validation loss. Early stop counter: 9/30
Epoch [42/1000], Training Loss: 0.0717
Validation Loss: 0.0690
No improvement in validation loss. Early stop counter: 10/30
Epoch [43/1000], Training Loss: 0.0690
Validation Loss: 0.0695
No improvement in validation loss. Early stop counter: 11/30
Epoch [44/1000], Training Loss: 0.0685
Validation Loss: 0.0686
New best model found with validation loss: 0.0686
Epoch [45/1000], Training Loss: 0.0684
Validation Loss: 0.0689
No improvement in validation loss. Early stop counter: 1/30
Epoch [46/1000], Training Loss: 0.0694
Validation Loss: 0.0693
No improvement in validation loss. Early stop counter: 2/30
Epoch [47/1000], Training Loss: 0.0684
Validation Loss: 0.0704
No improvement in validation loss. Early stop counter: 3/30
Epoch [48/1000], Training Loss: 0.0698
Validation Loss: 0.0691
No improvement in validation loss. Early stop counter: 4/30
Epoch [49/1000], Training Loss: 0.0701
Validation Loss: 0.0700
No improvement in validation loss. Early stop counter: 5/30
Epoch [50/1000], Training Loss: 0.0683
Validation Loss: 0.0689
No improvement in validation loss. Early stop counter: 6/30
Epoch [51/1000], Training Loss: 0.0682
Validation Loss: 0.0685
New best model found with validation loss: 0.0685
Epoch [52/1000], Training Loss: 0.0679
Validation Loss: 0.0684
New best model found with validation loss: 0.0684
Epoch [53/1000], Training Loss: 0.0683
Validation Loss: 0.0688
No improvement in validation loss. Early stop counter: 1/30
Epoch [54/1000], Training Loss: 0.0686
Validation Loss: 0.0694
No improvement in validation loss. Early stop counter: 2/30
Epoch [55/1000], Training Loss: 0.0686
Validation Loss: 0.0693
No improvement in validation loss. Early stop counter: 3/30
Epoch [56/1000], Training Loss: 0.0679
Validation Loss: 0.0689
No improvement in validation loss. Early stop counter: 4/30
Epoch [57/1000], Training Loss: 0.0679
Validation Loss: 0.0684
No improvement in validation loss. Early stop counter: 5/30
Epoch [58/1000], Training Loss: 0.0685
Validation Loss: 0.0690
No improvement in validation loss. Early stop counter: 6/30
Epoch [59/1000], Training Loss: 0.0681
Validation Loss: 0.0743
No improvement in validation loss. Early stop counter: 7/30
Epoch [60/1000], Training Loss: 0.0685
Validation Loss: 0.0686
No improvement in validation loss. Early stop counter: 8/30
Epoch [61/1000], Training Loss: 0.0680
Validation Loss: 0.0698
No improvement in validation loss. Early stop counter: 9/30
Epoch [62/1000], Training Loss: 0.0681
Validation Loss: 0.0683
New best model found with validation loss: 0.0683
Epoch [63/1000], Training Loss: 0.0686
Validation Loss: 0.0686
No improvement in validation loss. Early stop counter: 1/30
Epoch [64/1000], Training Loss: 0.0682
Validation Loss: 0.0686
No improvement in validation loss. Early stop counter: 2/30
Epoch [65/1000], Training Loss: 0.0682
Validation Loss: 0.0693
No improvement in validation loss. Early stop counter: 3/30
Epoch [66/1000], Training Loss: 0.0684
Validation Loss: 0.0692
No improvement in validation loss. Early stop counter: 4/30
Epoch [67/1000], Training Loss: 0.0678
Validation Loss: 0.0692
No improvement in validation loss. Early stop counter: 5/30
Epoch [68/1000], Training Loss: 0.0675
Validation Loss: 0.0697
No improvement in validation loss. Early stop counter: 6/30
NaN detected in loss; skipping this batch.
Epoch [69/1000], Training Loss: 0.0671
Validation Loss: 0.0683
No improvement in validation loss. Early stop counter: 7/30
NaN detected in loss; skipping this batch.
Epoch [70/1000], Training Loss: 0.0667
Validation Loss: 0.0681
New best model found with validation loss: 0.0681
NaN detected in loss; skipping this batch.
Epoch [71/1000], Training Loss: 0.0665
Validation Loss: 0.0687
No improvement in validation loss. Early stop counter: 1/30
NaN detected in loss; skipping this batch.
Epoch [72/1000], Training Loss: 0.0666
Validation Loss: 0.0684
No improvement in validation loss. Early stop counter: 2/30
NaN detected in loss; skipping this batch.
Epoch [73/1000], Training Loss: 0.0664
Validation Loss: 0.0690
No improvement in validation loss. Early stop counter: 3/30
NaN detected in loss; skipping this batch.
Epoch [74/1000], Training Loss: 0.0667
Validation Loss: 0.0687
No improvement in validation loss. Early stop counter: 4/30
NaN detected in loss; skipping this batch.
Epoch [75/1000], Training Loss: 0.0670
Validation Loss: 0.0699
No improvement in validation loss. Early stop counter: 5/30
NaN detected in loss; skipping this batch.
Epoch [76/1000], Training Loss: 0.0664
Validation Loss: nan
No improvement in validation loss. Early stop counter: 6/30
NaN detected in loss; skipping this batch.
Epoch [77/1000], Training Loss: 0.0681
Validation Loss: 0.0689
No improvement in validation loss. Early stop counter: 7/30
NaN detected in loss; skipping this batch.
Epoch [78/1000], Training Loss: 0.0669
Validation Loss: nan
No improvement in validation loss. Early stop counter: 8/30
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
Epoch [79/1000], Training Loss: 0.0678
Validation Loss: nan
No improvement in validation loss. Early stop counter: 9/30
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
Epoch [80/1000], Training Loss: 0.0664
Validation Loss: nan
No improvement in validation loss. Early stop counter: 10/30
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
Epoch [81/1000], Training Loss: 0.0652
Validation Loss: nan
No improvement in validation loss. Early stop counter: 11/30
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
Epoch [82/1000], Training Loss: 0.0650
Validation Loss: nan
No improvement in validation loss. Early stop counter: 12/30
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
Epoch [83/1000], Training Loss: 0.0655
Validation Loss: nan
No improvement in validation loss. Early stop counter: 13/30
NaN detected in loss; skipping this batch.
Epoch [84/1000], Training Loss: 0.0662
Validation Loss: nan
No improvement in validation loss. Early stop counter: 14/30
NaN detected in loss; skipping this batch.
Epoch [85/1000], Training Loss: 0.0662
Validation Loss: nan
No improvement in validation loss. Early stop counter: 15/30
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
Epoch [86/1000], Training Loss: 0.0632
Validation Loss: nan
No improvement in validation loss. Early stop counter: 16/30
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
Epoch [87/1000], Training Loss: 0.0600
Validation Loss: nan
No improvement in validation loss. Early stop counter: 17/30
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
Epoch [88/1000], Training Loss: 0.0593
Validation Loss: nan
No improvement in validation loss. Early stop counter: 18/30
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
Epoch [89/1000], Training Loss: 0.0594
Validation Loss: nan
No improvement in validation loss. Early stop counter: 19/30
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
Epoch [90/1000], Training Loss: 0.0578
Validation Loss: nan
No improvement in validation loss. Early stop counter: 20/30
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
Epoch [91/1000], Training Loss: 0.0521
Validation Loss: nan
No improvement in validation loss. Early stop counter: 21/30
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
Epoch [92/1000], Training Loss: 0.0500
Validation Loss: nan
No improvement in validation loss. Early stop counter: 22/30
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
Epoch [93/1000], Training Loss: 0.0480
Validation Loss: nan
No improvement in validation loss. Early stop counter: 23/30
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
Epoch [94/1000], Training Loss: 0.0472
Validation Loss: nan
No improvement in validation loss. Early stop counter: 24/30
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
Epoch [95/1000], Training Loss: 0.0437
Validation Loss: nan
No improvement in validation loss. Early stop counter: 25/30
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
Epoch [96/1000], Training Loss: 0.0436
Validation Loss: nan
No improvement in validation loss. Early stop counter: 26/30
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
Epoch [97/1000], Training Loss: 0.0390
Validation Loss: nan
No improvement in validation loss. Early stop counter: 27/30
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
Epoch [98/1000], Training Loss: 0.0371
Validation Loss: nan
No improvement in validation loss. Early stop counter: 28/30
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
Epoch [99/1000], Training Loss: 0.0390
Validation Loss: nan
No improvement in validation loss. Early stop counter: 29/30
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
NaN detected in loss; skipping this batch.
Epoch [100/1000], Training Loss: 0.0315
Validation Loss: nan
No improvement in validation loss. Early stop counter: 30/30
Early stopping triggered after 100 epochs.
Best model saved successfully.
Submitted batch job 45082996
