{'batch_size': 8, 'sequence_file': 'preprocessed_seq_ab_train_1200.npz', 'pt_file': 'pt_train_data.csv', 'seq_len': 1200, 'vocab_size': 22, 'embed_dim': 128, 'num_heads': 8, 'num_layers': 1, 'num_classes': 2, 'num_epochs': 1000, 'learning_rate': 0.0001, 'max_grad_norm': 0.1, 'validation_split': 0.1, 'early_stop_patience': 30, 'initial_gradient_noise_std': 0.05}
Number of GPUs available: 1
Initializing ParatopeModel with 1 self-attention layers...
Epoch [1/1000], Training Loss: 0.7075, Gradient Noise Std: 0.050000
Validation Loss: 0.6380
New best model found with validation loss: 0.6380
Epoch [2/1000], Training Loss: 0.6411, Gradient Noise Std: 0.045000
Validation Loss: 0.6311
New best model found with validation loss: 0.6311
Epoch [3/1000], Training Loss: 0.6296, Gradient Noise Std: 0.040500
Validation Loss: 0.6295
New best model found with validation loss: 0.6295
Epoch [4/1000], Training Loss: 0.6245, Gradient Noise Std: 0.036450
Validation Loss: 0.6229
New best model found with validation loss: 0.6229
Epoch [5/1000], Training Loss: 0.6203, Gradient Noise Std: 0.032805
Validation Loss: 0.6240
No improvement in validation loss. Early stop counter: 1/30
Epoch [6/1000], Training Loss: 0.6184, Gradient Noise Std: 0.029525
Validation Loss: 0.6218
New best model found with validation loss: 0.6218
Epoch [7/1000], Training Loss: 0.6161, Gradient Noise Std: 0.026572
Validation Loss: 0.6181
New best model found with validation loss: 0.6181
Epoch [8/1000], Training Loss: 0.6157, Gradient Noise Std: 0.023915
Validation Loss: 0.6237
No improvement in validation loss. Early stop counter: 1/30
Epoch [9/1000], Training Loss: 0.6116, Gradient Noise Std: 0.021523
Validation Loss: 0.6182
No improvement in validation loss. Early stop counter: 2/30
Epoch [10/1000], Training Loss: 0.6086, Gradient Noise Std: 0.019371
Validation Loss: 0.6127
New best model found with validation loss: 0.6127
Epoch [11/1000], Training Loss: 0.6065, Gradient Noise Std: 0.017434
Validation Loss: 0.6113
New best model found with validation loss: 0.6113
Epoch [12/1000], Training Loss: 0.6051, Gradient Noise Std: 0.015691
Validation Loss: 0.6161
No improvement in validation loss. Early stop counter: 1/30
Epoch [13/1000], Training Loss: 0.6034, Gradient Noise Std: 0.014121
Validation Loss: 0.6134
No improvement in validation loss. Early stop counter: 2/30
Epoch [14/1000], Training Loss: 0.6035, Gradient Noise Std: 0.012709
Validation Loss: 0.6114
No improvement in validation loss. Early stop counter: 3/30
Epoch [15/1000], Training Loss: 0.6026, Gradient Noise Std: 0.011438
Validation Loss: 0.6112
New best model found with validation loss: 0.6112
Epoch [16/1000], Training Loss: 0.6019, Gradient Noise Std: 0.010295
Validation Loss: 0.6116
No improvement in validation loss. Early stop counter: 1/30
Epoch [17/1000], Training Loss: 0.6009, Gradient Noise Std: 0.009265
Validation Loss: 0.6067
New best model found with validation loss: 0.6067
Epoch [18/1000], Training Loss: 0.5997, Gradient Noise Std: 0.008339
Validation Loss: 0.6081
No improvement in validation loss. Early stop counter: 1/30
Epoch [19/1000], Training Loss: 0.5997, Gradient Noise Std: 0.007505
Validation Loss: 0.6139
No improvement in validation loss. Early stop counter: 2/30
Epoch [20/1000], Training Loss: 0.5983, Gradient Noise Std: 0.006754
Validation Loss: 0.6041
New best model found with validation loss: 0.6041
Epoch [21/1000], Training Loss: 0.5961, Gradient Noise Std: 0.006079
Validation Loss: 0.6041
No improvement in validation loss. Early stop counter: 1/30
Epoch [22/1000], Training Loss: 0.5967, Gradient Noise Std: 0.005471
Validation Loss: 0.6044
No improvement in validation loss. Early stop counter: 2/30
Epoch [23/1000], Training Loss: 0.5960, Gradient Noise Std: 0.004924
Validation Loss: 0.6038
New best model found with validation loss: 0.6038
Epoch [24/1000], Training Loss: 0.5951, Gradient Noise Std: 0.004431
Validation Loss: 0.6043
No improvement in validation loss. Early stop counter: 1/30
Epoch [25/1000], Training Loss: 0.5942, Gradient Noise Std: 0.003988
Validation Loss: 0.6028
New best model found with validation loss: 0.6028
Epoch [26/1000], Training Loss: 0.5951, Gradient Noise Std: 0.003589
Validation Loss: 0.6014
New best model found with validation loss: 0.6014
Epoch [27/1000], Training Loss: 0.5944, Gradient Noise Std: 0.003231
Validation Loss: 0.6021
No improvement in validation loss. Early stop counter: 1/30
Epoch [28/1000], Training Loss: 0.5934, Gradient Noise Std: 0.002907
Validation Loss: 0.6015
No improvement in validation loss. Early stop counter: 2/30
Epoch [29/1000], Training Loss: 0.5931, Gradient Noise Std: 0.002617
Validation Loss: 0.6010
New best model found with validation loss: 0.6010
Epoch [30/1000], Training Loss: 0.5937, Gradient Noise Std: 0.002355
Validation Loss: 0.6010
No improvement in validation loss. Early stop counter: 1/30
Epoch [31/1000], Training Loss: 0.5919, Gradient Noise Std: 0.002120
Validation Loss: 0.6002
New best model found with validation loss: 0.6002
Epoch [32/1000], Training Loss: 0.5914, Gradient Noise Std: 0.001908
Validation Loss: 0.6027
No improvement in validation loss. Early stop counter: 1/30
Epoch [33/1000], Training Loss: 0.5911, Gradient Noise Std: 0.001717
Validation Loss: 0.6002
No improvement in validation loss. Early stop counter: 2/30
Epoch [34/1000], Training Loss: 0.5910, Gradient Noise Std: 0.001545
Validation Loss: 0.6000
New best model found with validation loss: 0.6000
Epoch [35/1000], Training Loss: 0.5908, Gradient Noise Std: 0.001391
Validation Loss: 0.6019
No improvement in validation loss. Early stop counter: 1/30
Epoch [36/1000], Training Loss: 0.5908, Gradient Noise Std: 0.001252
Validation Loss: 0.6105
No improvement in validation loss. Early stop counter: 2/30
Epoch [37/1000], Training Loss: 0.5907, Gradient Noise Std: 0.001126
Validation Loss: 0.5995
New best model found with validation loss: 0.5995
Epoch [38/1000], Training Loss: 0.5901, Gradient Noise Std: 0.001014
Validation Loss: 0.6002
No improvement in validation loss. Early stop counter: 1/30
Epoch [39/1000], Training Loss: 0.5897, Gradient Noise Std: 0.000912
Validation Loss: 0.5988
New best model found with validation loss: 0.5988
Epoch [40/1000], Training Loss: 0.5900, Gradient Noise Std: 0.000821
Validation Loss: 0.6002
No improvement in validation loss. Early stop counter: 1/30
Epoch [41/1000], Training Loss: 0.5891, Gradient Noise Std: 0.000739
Validation Loss: 0.6006
No improvement in validation loss. Early stop counter: 2/30
Epoch [42/1000], Training Loss: 0.5890, Gradient Noise Std: 0.000665
Validation Loss: 0.5982
New best model found with validation loss: 0.5982
Epoch [43/1000], Training Loss: 0.5889, Gradient Noise Std: 0.000599
Validation Loss: 0.5982
New best model found with validation loss: 0.5982
Epoch [44/1000], Training Loss: 0.5888, Gradient Noise Std: 0.000539
Validation Loss: 0.6009
No improvement in validation loss. Early stop counter: 1/30
Epoch [45/1000], Training Loss: 0.5892, Gradient Noise Std: 0.000485
Validation Loss: 0.5986
No improvement in validation loss. Early stop counter: 2/30
Epoch [46/1000], Training Loss: 0.5882, Gradient Noise Std: 0.000436
Validation Loss: 0.6003
No improvement in validation loss. Early stop counter: 3/30
Epoch [47/1000], Training Loss: 0.5885, Gradient Noise Std: 0.000393
Validation Loss: 0.5994
No improvement in validation loss. Early stop counter: 4/30
Epoch [48/1000], Training Loss: 0.5885, Gradient Noise Std: 0.000353
Validation Loss: 0.5986
No improvement in validation loss. Early stop counter: 5/30
Epoch [49/1000], Training Loss: 0.5878, Gradient Noise Std: 0.000318
Validation Loss: 0.5984
No improvement in validation loss. Early stop counter: 6/30
Epoch [50/1000], Training Loss: 0.5882, Gradient Noise Std: 0.000286
Validation Loss: 0.5981
New best model found with validation loss: 0.5981
Epoch [51/1000], Training Loss: 0.5879, Gradient Noise Std: 0.000258
Validation Loss: 0.5978
New best model found with validation loss: 0.5978
Epoch [52/1000], Training Loss: 0.5877, Gradient Noise Std: 0.000232
Validation Loss: 0.5979
No improvement in validation loss. Early stop counter: 1/30
Epoch [53/1000], Training Loss: 0.5876, Gradient Noise Std: 0.000209
Validation Loss: 0.5975
New best model found with validation loss: 0.5975
Epoch [54/1000], Training Loss: 0.5877, Gradient Noise Std: 0.000188
Validation Loss: 0.5979
No improvement in validation loss. Early stop counter: 1/30
Epoch [55/1000], Training Loss: 0.5874, Gradient Noise Std: 0.000169
Validation Loss: 0.5982
No improvement in validation loss. Early stop counter: 2/30
Epoch [56/1000], Training Loss: 0.5879, Gradient Noise Std: 0.000152
Validation Loss: 0.5977
No improvement in validation loss. Early stop counter: 3/30
Epoch [57/1000], Training Loss: 0.5874, Gradient Noise Std: 0.000137
Validation Loss: 0.5975
No improvement in validation loss. Early stop counter: 4/30
Epoch [58/1000], Training Loss: 0.5876, Gradient Noise Std: 0.000123
Validation Loss: 0.5974
New best model found with validation loss: 0.5974
Epoch [59/1000], Training Loss: 0.5877, Gradient Noise Std: 0.000111
Validation Loss: 0.5978
No improvement in validation loss. Early stop counter: 1/30
Epoch [60/1000], Training Loss: 0.5873, Gradient Noise Std: 0.000100
Validation Loss: 0.5971
New best model found with validation loss: 0.5971
Epoch [61/1000], Training Loss: 0.5875, Gradient Noise Std: 0.000090
Validation Loss: 0.5973
No improvement in validation loss. Early stop counter: 1/30
Epoch [62/1000], Training Loss: 0.5877, Gradient Noise Std: 0.000081
Validation Loss: 0.5972
No improvement in validation loss. Early stop counter: 2/30
Epoch [63/1000], Training Loss: 0.5873, Gradient Noise Std: 0.000073
Validation Loss: 0.5972
No improvement in validation loss. Early stop counter: 3/30
Epoch [64/1000], Training Loss: 0.5870, Gradient Noise Std: 0.000066
Validation Loss: 0.5978
No improvement in validation loss. Early stop counter: 4/30
Epoch [65/1000], Training Loss: 0.5868, Gradient Noise Std: 0.000059
Validation Loss: 0.5979
No improvement in validation loss. Early stop counter: 5/30
Epoch [66/1000], Training Loss: 0.5871, Gradient Noise Std: 0.000053
Validation Loss: 0.5976
No improvement in validation loss. Early stop counter: 6/30
Epoch [67/1000], Training Loss: 0.5871, Gradient Noise Std: 0.000048
Validation Loss: 0.5972
No improvement in validation loss. Early stop counter: 7/30
Epoch [68/1000], Training Loss: 0.5871, Gradient Noise Std: 0.000043
Validation Loss: 0.5970
New best model found with validation loss: 0.5970
Epoch [69/1000], Training Loss: 0.5868, Gradient Noise Std: 0.000039
Validation Loss: 0.5990
No improvement in validation loss. Early stop counter: 1/30
Epoch [70/1000], Training Loss: 0.5872, Gradient Noise Std: 0.000035
Validation Loss: 0.5974
No improvement in validation loss. Early stop counter: 2/30
Epoch [71/1000], Training Loss: 0.5870, Gradient Noise Std: 0.000031
Validation Loss: 0.5971
No improvement in validation loss. Early stop counter: 3/30
Epoch [72/1000], Training Loss: 0.5865, Gradient Noise Std: 0.000028
Validation Loss: 0.5971
No improvement in validation loss. Early stop counter: 4/30
Epoch [73/1000], Training Loss: 0.5865, Gradient Noise Std: 0.000025
Validation Loss: 0.5971
No improvement in validation loss. Early stop counter: 5/30
Epoch [74/1000], Training Loss: 0.5865, Gradient Noise Std: 0.000023
Validation Loss: 0.5979
No improvement in validation loss. Early stop counter: 6/30
Epoch [75/1000], Training Loss: 0.5869, Gradient Noise Std: 0.000021
Validation Loss: 0.5969
New best model found with validation loss: 0.5969
Epoch [76/1000], Training Loss: 0.5865, Gradient Noise Std: 0.000018
Validation Loss: 0.5969
No improvement in validation loss. Early stop counter: 1/30
Epoch [77/1000], Training Loss: 0.5866, Gradient Noise Std: 0.000017
Validation Loss: 0.5973
No improvement in validation loss. Early stop counter: 2/30
Epoch [78/1000], Training Loss: 0.5867, Gradient Noise Std: 0.000015
Validation Loss: 0.5974
No improvement in validation loss. Early stop counter: 3/30
Epoch [79/1000], Training Loss: 0.5868, Gradient Noise Std: 0.000013
Validation Loss: 0.5971
No improvement in validation loss. Early stop counter: 4/30
Epoch [80/1000], Training Loss: 0.5865, Gradient Noise Std: 0.000012
Validation Loss: 0.5968
New best model found with validation loss: 0.5968
Epoch [81/1000], Training Loss: 0.5865, Gradient Noise Std: 0.000011
Validation Loss: 0.5969
No improvement in validation loss. Early stop counter: 1/30
Epoch [82/1000], Training Loss: 0.5867, Gradient Noise Std: 0.000010
Validation Loss: 0.5971
No improvement in validation loss. Early stop counter: 2/30
Epoch [83/1000], Training Loss: 0.5866, Gradient Noise Std: 0.000009
Validation Loss: 0.5969
No improvement in validation loss. Early stop counter: 3/30
Epoch [84/1000], Training Loss: 0.5865, Gradient Noise Std: 0.000008
Validation Loss: 0.5970
No improvement in validation loss. Early stop counter: 4/30
Epoch [85/1000], Training Loss: 0.5865, Gradient Noise Std: 0.000007
Validation Loss: 0.5976
No improvement in validation loss. Early stop counter: 5/30
Epoch [86/1000], Training Loss: 0.5864, Gradient Noise Std: 0.000006
Validation Loss: 0.5971
No improvement in validation loss. Early stop counter: 6/30
Epoch [87/1000], Training Loss: 0.5865, Gradient Noise Std: 0.000006
Validation Loss: 0.5972
No improvement in validation loss. Early stop counter: 7/30
Epoch [88/1000], Training Loss: 0.5864, Gradient Noise Std: 0.000005
Validation Loss: 0.5971
No improvement in validation loss. Early stop counter: 8/30
Epoch [89/1000], Training Loss: 0.5862, Gradient Noise Std: 0.000005
Validation Loss: 0.5972
No improvement in validation loss. Early stop counter: 9/30
Epoch [90/1000], Training Loss: 0.5865, Gradient Noise Std: 0.000004
Validation Loss: 0.5969
No improvement in validation loss. Early stop counter: 10/30
Epoch [91/1000], Training Loss: 0.5864, Gradient Noise Std: 0.000004
Validation Loss: 0.5970
No improvement in validation loss. Early stop counter: 11/30
Epoch [92/1000], Training Loss: 0.5864, Gradient Noise Std: 0.000003
Validation Loss: 0.5970
No improvement in validation loss. Early stop counter: 12/30
Epoch [93/1000], Training Loss: 0.5867, Gradient Noise Std: 0.000003
Validation Loss: 0.5971
No improvement in validation loss. Early stop counter: 13/30
Epoch [94/1000], Training Loss: 0.5866, Gradient Noise Std: 0.000003
Validation Loss: 0.5973
No improvement in validation loss. Early stop counter: 14/30
Epoch [95/1000], Training Loss: 0.5863, Gradient Noise Std: 0.000002
Validation Loss: 0.5971
No improvement in validation loss. Early stop counter: 15/30
Epoch [96/1000], Training Loss: 0.5867, Gradient Noise Std: 0.000002
Validation Loss: 0.5971
No improvement in validation loss. Early stop counter: 16/30
Epoch [97/1000], Training Loss: 0.5866, Gradient Noise Std: 0.000002
Validation Loss: 0.5971
No improvement in validation loss. Early stop counter: 17/30
Epoch [98/1000], Training Loss: 0.5866, Gradient Noise Std: 0.000002
Validation Loss: 0.5970
No improvement in validation loss. Early stop counter: 18/30
Epoch [99/1000], Training Loss: 0.5864, Gradient Noise Std: 0.000002
Validation Loss: 0.5971
No improvement in validation loss. Early stop counter: 19/30
Epoch [100/1000], Training Loss: 0.5864, Gradient Noise Std: 0.000001
Validation Loss: 0.5970
No improvement in validation loss. Early stop counter: 20/30
Epoch [101/1000], Training Loss: 0.5865, Gradient Noise Std: 0.000001
Validation Loss: 0.5970
No improvement in validation loss. Early stop counter: 21/30
Epoch [102/1000], Training Loss: 0.5863, Gradient Noise Std: 0.000001
Validation Loss: 0.5970
No improvement in validation loss. Early stop counter: 22/30
Epoch [103/1000], Training Loss: 0.5863, Gradient Noise Std: 0.000001
Validation Loss: 0.5970
No improvement in validation loss. Early stop counter: 23/30
Epoch [104/1000], Training Loss: 0.5864, Gradient Noise Std: 0.000001
Validation Loss: 0.5970
No improvement in validation loss. Early stop counter: 24/30
Epoch [105/1000], Training Loss: 0.5862, Gradient Noise Std: 0.000001
Validation Loss: 0.5970
No improvement in validation loss. Early stop counter: 25/30
Epoch [106/1000], Training Loss: 0.5864, Gradient Noise Std: 0.000001
Validation Loss: 0.5971
No improvement in validation loss. Early stop counter: 26/30
Epoch [107/1000], Training Loss: 0.5863, Gradient Noise Std: 0.000001
Validation Loss: 0.5970
No improvement in validation loss. Early stop counter: 27/30
Epoch [108/1000], Training Loss: 0.5860, Gradient Noise Std: 0.000001
Validation Loss: 0.5970
No improvement in validation loss. Early stop counter: 28/30
Epoch [109/1000], Training Loss: 0.5863, Gradient Noise Std: 0.000001
Validation Loss: 0.5970
No improvement in validation loss. Early stop counter: 29/30
Epoch [110/1000], Training Loss: 0.5863, Gradient Noise Std: 0.000001
Validation Loss: 0.5970
No improvement in validation loss. Early stop counter: 30/30
Early stopping triggered after 110 epochs.
Best model saved successfully.
