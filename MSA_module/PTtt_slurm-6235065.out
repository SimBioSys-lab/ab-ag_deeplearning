{'batch_size': 4, 'sequence_file_train': 'para_train_sequences_3000.npz', 'data_file_train': 'para_train_interfaces_3000.npz', 'edge_file_train': 'para_train_edges_3000.npz', 'sequence_file_val': 'para_val_sequences_3000.npz', 'data_file_val': 'para_val_interfaces_3000.npz', 'edge_file_val': 'para_val_edges_3000.npz', 'max_len': 3000, 'vocab_size': 23, 'embed_dim': 256, 'num_heads': 16, 'dropout': 0.0, 'num_layers': 1, 'num_gnn_layers': 2, 'num_int_layers': 1, 'num_classes': 2, 'num_epochs': 1000, 'learning_rate': 0.0001, 'max_grad_norm': 0.1, 'early_stop_patience': 10, 'initial_gradient_noise_std': 0.05, 'accumulation_steps': 2}
Number of GPUs available: 4
Initializing ClassificationModel with 2 GAT layers and residual connections...
Initializing MCModel with 2 GAT layers and 1 row attention layers...
Initializing CGModel with 2 GAT layers and residual connections...
Initializing CoreModel with 1 self-attention layers...
Using 4 GPUs with DataParallel.
Epoch [1/1000], Training Loss: 0.4298
Validation Loss: 0.4682
New best model saved with validation loss: 0.4682
Epoch [2/1000], Training Loss: 0.3827
Validation Loss: 0.3669
New best model saved with validation loss: 0.3669
Epoch [3/1000], Training Loss: 0.3452
Validation Loss: 0.3530
New best model saved with validation loss: 0.3530
Epoch [4/1000], Training Loss: 0.3433
Validation Loss: 0.3471
New best model saved with validation loss: 0.3471
Epoch [5/1000], Training Loss: 0.3236
Validation Loss: 0.3411
New best model saved with validation loss: 0.3411
Epoch [6/1000], Training Loss: 0.3184
Validation Loss: 0.3219
New best model saved with validation loss: 0.3219
Epoch [7/1000], Training Loss: 0.3242
Validation Loss: 0.3239
No improvement in validation loss. Early stop counter: 1/10
Epoch [8/1000], Training Loss: 0.3030
Validation Loss: 0.3197
New best model saved with validation loss: 0.3197
Epoch [9/1000], Training Loss: 0.3013
Validation Loss: 0.3155
New best model saved with validation loss: 0.3155
Epoch [10/1000], Training Loss: 0.2891
Validation Loss: 0.3329
No improvement in validation loss. Early stop counter: 1/10
Epoch [11/1000], Training Loss: 0.2817
Validation Loss: 0.3158
No improvement in validation loss. Early stop counter: 2/10
Epoch [12/1000], Training Loss: 0.2774
Validation Loss: 0.3064
New best model saved with validation loss: 0.3064
Epoch [13/1000], Training Loss: 0.2769
Validation Loss: 0.3008
New best model saved with validation loss: 0.3008
Epoch [14/1000], Training Loss: 0.2741
Validation Loss: 0.3156
No improvement in validation loss. Early stop counter: 1/10
Epoch [15/1000], Training Loss: 0.2744
Validation Loss: 0.3203
No improvement in validation loss. Early stop counter: 2/10
Epoch [16/1000], Training Loss: 0.2729
Validation Loss: 0.3013
No improvement in validation loss. Early stop counter: 3/10
Epoch [17/1000], Training Loss: 0.2682
Validation Loss: 0.2993
New best model saved with validation loss: 0.2993
Epoch [18/1000], Training Loss: 0.2688
Validation Loss: 0.3133
No improvement in validation loss. Early stop counter: 1/10
Epoch [19/1000], Training Loss: 0.2664
Validation Loss: 0.3123
No improvement in validation loss. Early stop counter: 2/10
Epoch [20/1000], Training Loss: 0.2648
Validation Loss: 0.3019
No improvement in validation loss. Early stop counter: 3/10
Epoch [21/1000], Training Loss: 0.2595
Validation Loss: 0.2977
New best model saved with validation loss: 0.2977
Epoch [22/1000], Training Loss: 0.2603
Validation Loss: 0.3006
No improvement in validation loss. Early stop counter: 1/10
Epoch [23/1000], Training Loss: 0.2577
Validation Loss: 0.2959
New best model saved with validation loss: 0.2959
Epoch [24/1000], Training Loss: 0.2579
Validation Loss: 0.3014
No improvement in validation loss. Early stop counter: 1/10
Epoch [25/1000], Training Loss: 0.2574
Validation Loss: 0.2951
New best model saved with validation loss: 0.2951
Epoch [26/1000], Training Loss: 0.2573
Validation Loss: 0.2935
New best model saved with validation loss: 0.2935
Epoch [27/1000], Training Loss: 0.2550
Validation Loss: 0.2970
No improvement in validation loss. Early stop counter: 1/10
Epoch [28/1000], Training Loss: 0.2552
Validation Loss: 0.2945
No improvement in validation loss. Early stop counter: 2/10
Epoch [29/1000], Training Loss: 0.2547
Validation Loss: 0.2929
New best model saved with validation loss: 0.2929
Epoch [30/1000], Training Loss: 0.2536
Validation Loss: 0.2925
New best model saved with validation loss: 0.2925
Epoch [31/1000], Training Loss: 0.2507
Validation Loss: 0.2953
No improvement in validation loss. Early stop counter: 1/10
Epoch [32/1000], Training Loss: 0.2508
Validation Loss: 0.2965
No improvement in validation loss. Early stop counter: 2/10
Epoch [33/1000], Training Loss: 0.2494
Validation Loss: 0.2921
New best model saved with validation loss: 0.2921
Epoch [34/1000], Training Loss: 0.2492
Validation Loss: 0.2974
No improvement in validation loss. Early stop counter: 1/10
Epoch [35/1000], Training Loss: 0.2503
Validation Loss: 0.2931
No improvement in validation loss. Early stop counter: 2/10
Epoch [36/1000], Training Loss: 0.2493
Validation Loss: 0.2941
No improvement in validation loss. Early stop counter: 3/10
Epoch [37/1000], Training Loss: 0.2485
Validation Loss: 0.2958
No improvement in validation loss. Early stop counter: 4/10
Epoch [38/1000], Training Loss: 0.2477
Validation Loss: 0.2930
No improvement in validation loss. Early stop counter: 5/10
Epoch [39/1000], Training Loss: 0.2490
Validation Loss: 0.2935
No improvement in validation loss. Early stop counter: 6/10
Epoch [40/1000], Training Loss: 0.2489
Validation Loss: 0.2967
No improvement in validation loss. Early stop counter: 7/10
Epoch [41/1000], Training Loss: 0.2478
Validation Loss: 0.2941
No improvement in validation loss. Early stop counter: 8/10
Epoch [42/1000], Training Loss: 0.2465
Validation Loss: 0.2964
No improvement in validation loss. Early stop counter: 9/10
Epoch [43/1000], Training Loss: 0.2463
Validation Loss: 0.2938
No improvement in validation loss. Early stop counter: 10/10
Early stopping triggered after 43 epochs.
