{'batch_size': 4, 'sequence_file_train': 'para_train_sequences_3000.npz', 'data_file_train': 'para_train_interfaces_3000.npz', 'edge_file_train': 'para_train_edges_3000.npz', 'sequence_file_val': 'para_val_sequences_3000.npz', 'data_file_val': 'para_val_interfaces_3000.npz', 'edge_file_val': 'para_val_edges_3000.npz', 'max_len': 3000, 'vocab_size': 23, 'embed_dim': 256, 'num_heads': 16, 'dropout': 0.1, 'num_layers': 1, 'num_gnn_layers': 2, 'num_int_layers': 1, 'num_classes': 2, 'num_epochs': 1000, 'learning_rate': 0.0001, 'max_grad_norm': 0.1, 'early_stop_patience': 10, 'initial_gradient_noise_std': 0.05, 'accumulation_steps': 2}
Number of GPUs available: 4
Initializing ClassificationModel with 2 GAT layers and residual connections...
Initializing MCModel with 2 GAT layers and 1 row attention layers...
Initializing CGModel with 2 GAT layers and residual connections...
Initializing CoreModel with 1 self-attention layers...
Using 4 GPUs with DataParallel.
Epoch [1/1000], Training Loss: 0.4471
Validation Loss: 0.4443
New best model saved with validation loss: 0.4443
Epoch [2/1000], Training Loss: 0.3815
Validation Loss: 0.3768
New best model saved with validation loss: 0.3768
Epoch [3/1000], Training Loss: 0.3582
Validation Loss: 0.3458
New best model saved with validation loss: 0.3458
Epoch [4/1000], Training Loss: 0.3435
Validation Loss: 0.3449
New best model saved with validation loss: 0.3449
Epoch [5/1000], Training Loss: 0.3362
Validation Loss: 0.3408
New best model saved with validation loss: 0.3408
Epoch [6/1000], Training Loss: 0.3270
Validation Loss: 0.3715
No improvement in validation loss. Early stop counter: 1/10
Epoch [7/1000], Training Loss: 0.3275
Validation Loss: 0.3225
New best model saved with validation loss: 0.3225
Epoch [8/1000], Training Loss: 0.3149
Validation Loss: 0.3216
New best model saved with validation loss: 0.3216
Epoch [9/1000], Training Loss: 0.3182
Validation Loss: 0.3339
No improvement in validation loss. Early stop counter: 1/10
Epoch [10/1000], Training Loss: 0.3123
Validation Loss: 0.3373
No improvement in validation loss. Early stop counter: 2/10
Epoch [11/1000], Training Loss: 0.3012
Validation Loss: 0.3160
New best model saved with validation loss: 0.3160
Epoch [12/1000], Training Loss: 0.2984
Validation Loss: 0.3101
New best model saved with validation loss: 0.3101
Epoch [13/1000], Training Loss: 0.2981
Validation Loss: 0.3129
No improvement in validation loss. Early stop counter: 1/10
Epoch [14/1000], Training Loss: 0.2913
Validation Loss: 0.3157
No improvement in validation loss. Early stop counter: 2/10
Epoch [15/1000], Training Loss: 0.2913
Validation Loss: 0.3130
No improvement in validation loss. Early stop counter: 3/10
Epoch [16/1000], Training Loss: 0.2871
Validation Loss: 0.3034
New best model saved with validation loss: 0.3034
Epoch [17/1000], Training Loss: 0.2862
Validation Loss: 0.3037
No improvement in validation loss. Early stop counter: 1/10
Epoch [18/1000], Training Loss: 0.2870
Validation Loss: 0.3046
No improvement in validation loss. Early stop counter: 2/10
Epoch [19/1000], Training Loss: 0.2810
Validation Loss: 0.3106
No improvement in validation loss. Early stop counter: 3/10
Epoch [20/1000], Training Loss: 0.2828
Validation Loss: 0.3044
No improvement in validation loss. Early stop counter: 4/10
Epoch [21/1000], Training Loss: 0.2787
Validation Loss: 0.3027
New best model saved with validation loss: 0.3027
Epoch [22/1000], Training Loss: 0.2769
Validation Loss: 0.3006
New best model saved with validation loss: 0.3006
Epoch [23/1000], Training Loss: 0.2783
Validation Loss: 0.3003
New best model saved with validation loss: 0.3003
Epoch [24/1000], Training Loss: 0.2761
Validation Loss: 0.2993
New best model saved with validation loss: 0.2993
Epoch [25/1000], Training Loss: 0.2750
Validation Loss: 0.2971
New best model saved with validation loss: 0.2971
Epoch [26/1000], Training Loss: 0.2747
Validation Loss: 0.3024
No improvement in validation loss. Early stop counter: 1/10
Epoch [27/1000], Training Loss: 0.2736
Validation Loss: 0.3003
No improvement in validation loss. Early stop counter: 2/10
Epoch [28/1000], Training Loss: 0.2737
Validation Loss: 0.2993
No improvement in validation loss. Early stop counter: 3/10
Epoch [29/1000], Training Loss: 0.2741
Validation Loss: 0.3074
No improvement in validation loss. Early stop counter: 4/10
Epoch [30/1000], Training Loss: 0.2756
Validation Loss: 0.2995
No improvement in validation loss. Early stop counter: 5/10
Epoch [31/1000], Training Loss: 0.2715
Validation Loss: 0.2981
No improvement in validation loss. Early stop counter: 6/10
Epoch [32/1000], Training Loss: 0.2700
Validation Loss: 0.2961
New best model saved with validation loss: 0.2961
Epoch [33/1000], Training Loss: 0.2716
Validation Loss: 0.2985
No improvement in validation loss. Early stop counter: 1/10
Epoch [34/1000], Training Loss: 0.2703
Validation Loss: 0.2993
No improvement in validation loss. Early stop counter: 2/10
Epoch [35/1000], Training Loss: 0.2701
Validation Loss: 0.2977
No improvement in validation loss. Early stop counter: 3/10
Epoch [36/1000], Training Loss: 0.2711
Validation Loss: 0.2959
New best model saved with validation loss: 0.2959
Epoch [37/1000], Training Loss: 0.2700
Validation Loss: 0.2977
No improvement in validation loss. Early stop counter: 1/10
Epoch [38/1000], Training Loss: 0.2697
Validation Loss: 0.2947
New best model saved with validation loss: 0.2947
Epoch [39/1000], Training Loss: 0.2697
Validation Loss: 0.3000
No improvement in validation loss. Early stop counter: 1/10
Epoch [40/1000], Training Loss: 0.2693
Validation Loss: 0.2970
No improvement in validation loss. Early stop counter: 2/10
Epoch [41/1000], Training Loss: 0.2679
Validation Loss: 0.2961
No improvement in validation loss. Early stop counter: 3/10
Epoch [42/1000], Training Loss: 0.2690
Validation Loss: 0.3033
No improvement in validation loss. Early stop counter: 4/10
Epoch [43/1000], Training Loss: 0.2685
Validation Loss: 0.2963
No improvement in validation loss. Early stop counter: 5/10
Epoch [44/1000], Training Loss: 0.2666
Validation Loss: 0.2974
No improvement in validation loss. Early stop counter: 6/10
Epoch [45/1000], Training Loss: 0.2667
Validation Loss: 0.2963
No improvement in validation loss. Early stop counter: 7/10
Epoch [46/1000], Training Loss: 0.2686
Validation Loss: 0.2962
No improvement in validation loss. Early stop counter: 8/10
Epoch [47/1000], Training Loss: 0.2672
Validation Loss: 0.3016
No improvement in validation loss. Early stop counter: 9/10
Epoch [48/1000], Training Loss: 0.2674
Validation Loss: 0.3034
No improvement in validation loss. Early stop counter: 10/10
Early stopping triggered after 48 epochs.
